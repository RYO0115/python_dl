{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python DLL Chapter4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数\n",
    "損失関数はニューラルネットワークの性能の**悪さ**を示す指標。\n",
    "\n",
    "現在のニューラルネットワークが教師データに対してどれだけ適合していないか、教師データにたいして　どれだけ一致していないかということを表す。\n",
    "\n",
    "一般に二乗和誤差、交差エントロピー誤差が使われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二乗和誤差(mean squared error)\n",
    "最も有名な損失関数\n",
    "\n",
    "$$ E = \\frac{1}{2}\\sum_{k}{}(y_k-t_k)^2 $$\n",
    "\n",
    "$$\n",
    "y_k : ニューラルネットワークの出力　　\n",
    "t_k : 教師データ　　\n",
    "k   : 次元数\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanSquaredError(y, t):\n",
    "    error = 0.5 * np.sum((y-t)**2)\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先ほどのmnistでは教師データは以下のような形になっている。\n",
    "#下のtは2が正解となっている。\n",
    "#このような表記を\"one-hot表現\"という\n",
    "t = [0,0,1,0,0,0,0,0,0,0,]\n",
    "\n",
    "# \"2\"の確率が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanSquaredError(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"7\"の確率が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanSquaredError(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差エントロピー誤差(cross entropy error)\n",
    "\n",
    "$$ E = - \\sum_{k}{}t_k\\log y_k $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62a4bfec18>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y = log(x) のグラフ\n",
    "x = np.arange(0.01,1,0.01)\n",
    "y = np.log(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyError(y ,t):\n",
    "    delta = 1e-7\n",
    "    return(-np.sum(t*np.log(y+delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0,]\n",
    "\n",
    "# \"2\"の確率が最も高い場合\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropyError(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"7\"の確率が最も高い場合\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropyError(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチ学習\n",
    "上記の損失関数はひとつの訓練データに対しての関数。\n",
    "\n",
    "実際に訓練データが100個あれば、この損失関数は100個の損失関数の和を求め、最後に100で割って正規化をし、指標として利用する。\n",
    "\n",
    "交差エントロピー誤差を例にすると\n",
    "\n",
    "$$ E = -\\frac{1}{N} \\sum_{n}{}\\sum_{k}{}t_{nk} \\log y_{nk}\\ $$\n",
    "\n",
    "となる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、学習データが例えばmnistだと60,000枚あるとこの誤差を求めるのに時間がかかってしまう。\n",
    "\n",
    "そこで、訓練データの中から一定の枚数だけを選び出し(ミニバッチ)、そのミニバッチごとに学習を行う。\n",
    "\n",
    "これを**ミニバッチ学習**という。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ対応版\n",
    "def CrossEntoropyError( y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return(-np.sum(np.log(y[np.arrange(batch_size),t] + 1e-7))/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumericalGradient(f, x):\n",
    "    h = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        #f(x+h)\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        #f(x-h)\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "    return(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function2(x):\n",
    "    return(x[0]**2 + x[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericalGradient(Function2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumericalGradient(Function2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配法\n",
    "機械学習では学習の際に最適なパラメータを探す。\n",
    "ここで、最適なパラメータとは、損失関数が最小値を取る時のパラメータのこと。\n",
    "\n",
    "しかし、そうわかっていてもパラメータ空間は広大で、どこに最小値があるのかわからない。\n",
    "\n",
    "そこで、勾配をうまく利用して関数の最小値(あるいは、できるだけ小さい値)を探そうというのが勾配法。\n",
    "\n",
    "勾配の方向が必ず最小値に向かうという保証はないが、その方向にすすむことで関数の値を最も減らすことができる。\n",
    "\n",
    "そこで、勾配法では現在の場所から勾配方向に一定の距離だけ進み、移動した先でも勾配を求め、またその勾配方向へと移動する。\n",
    "このように繰り返し勾配方向へ進むことで関数の値を徐々に減らすのが**勾配法(gradient method)**。\n",
    "\n",
    "ちなみに勾配法は**最大値**を探す場合は**勾配上昇法**、逆に**最小値**を探す場合には**勾配降下法**と呼ばれる。\n",
    "ただ、結局これは符号の問題でしかないため、本質的な違いは存在しない。また、ニューラルネットでは主に降下法が使われている。\n",
    "\n",
    "勾配法:\n",
    "$$ x_0 = x_0 - \\eta\\frac{ \\partial f}{\\partial x_0}$$\n",
    "$$ x_1 = x_1 - \\eta\\frac{ \\partial f}{\\partial x_1}$$\n",
    "$$ \\eta : ニューラルネット学習率 $$\n",
    "\n",
    "学習率とは、一回の学習で、どれだけ学習させるか、どれだけパラメータを更新するかということを決めるパラメータ。\n",
    "\n",
    "上の数式は、一回のステップを示しており、実際にはこれを何度も繰り返しおこなっていくことで学習を進めていく。\n",
    "\n",
    "ここでは変数の数が増えてもそれぞれの変数の偏微分の値によって更新されることになる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent( function, init_x, learning_rate=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = NumericalGradient( function, x)\n",
    "        x -= learning_rate * grad\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Function2( x ):\n",
    "    return(x[0]**2 + x[1]**2)\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "# 学習率が大きすぎる例 learning_rate = 10.0\n",
    "GradientDescent( Function2, init_x, learning_rate = 10.0, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習率が小さすぎる例　learning_rate = 1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "GradientDescent( Function2, init_x, learning_rate = 1e-10, step_num = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この学習率のようなパラメータは一般に**ハイパーパラメータ**と呼ばれるもので、よく機械学習は最後は職人技と呼ばれる所以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にニューラルネットワークで求める必要がある勾配とは、重みパラメータに関する損失関数の勾配になる。\n",
    "例えば以下のような重みWがあった際、その損失関数Lの勾配は以下のようになる。\n",
    "\n",
    "$$ \n",
    "W = \\left[\\begin{array}{ccc}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "\\end{array}\\right] \\quad\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} =\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{\\partial L}{\\partial w_{11}} & \\frac{\\partial L}{\\partial w_{12}} & \\frac{\\partial L}{\\partial w_{13}} \\\\ \n",
    "\\frac{\\partial L}{\\partial w_{21}} & \\frac{\\partial L}{\\partial w_{22}} & \\frac{\\partial L}{\\partial w_{23}}\n",
    "\\end{array}\\right] \\quad\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
